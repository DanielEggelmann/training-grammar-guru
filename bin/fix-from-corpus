#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright 2016 Eddie Antonio Santos <easantos@ualberta.ca>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import argparse
from typing import Optional, Any

from sensibility import (
    Sensibility, Edit, Corpus, Vectors, SourceFile, vocabulary, Vind
)
from sensibility.fix import temporary_program
from sensibility._paths import VECTORS_PATH, SOURCES_PATH


def to_vind(text: str) -> Optional[Vind]:
    if len(text) == 0:
        return None
    else:
        return vocabulary.to_index(text)


def get_edit(args: Any) -> Edit:
    kind = args.kind
    new = ''

    if kind == 'i':
        new = args.token
    elif kind == 's':
        new = args.token

    new_token = to_vind(new)
    return Edit.deserialize(kind, args.location, new_token, Vind(0))


parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers()

parser_ins = subparsers.add_parser('insert')
parser_ins.add_argument('location', type=int)
parser_ins.add_argument('token', type=str)
parser_ins.set_defaults(kind='i')

parser_del = subparsers.add_parser('delete')
parser_del.add_argument('location', type=int)
parser_del.set_defaults(kind='x')

parser_sub = subparsers.add_parser('substitute')
parser_sub.add_argument('location', type=int)
parser_sub.add_argument('token', type=str)
parser_sub.set_defaults(kind='s')


parser.add_argument('filehash', type=str)



if __name__ == '__main__':
    args = parser.parse_args()
    filehash: str  = args.filehash
    edit = get_edit(args)

    SourceFile.corpus = Corpus.connect_to(SOURCES_PATH)
    SourceFile.vectors = Vectors.connect_to(VECTORS_PATH)

    original_file = SourceFile(filehash)
    assert original_file.source_tokens

    mutant = edit.apply(original_file.vector)

    print(edit)

    sensibility = Sensibility(0)
    with temporary_program(mutant) as mutated_file:
        print(mutated_file.name)
        # Do the (canned) prediction...
        ranked_locations, fixes = sensibility.rank_and_fix(mutated_file.name)

    print(ranked_locations)
    print(fixes)
