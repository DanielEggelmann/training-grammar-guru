#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

# Copyright 2017 Eddie Antonio Santos <easantos@ualberta.ca>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Mutate and predict on one fold.

Does not **evaluate**, simply mutates files and performs predictions.

This evaluation:
 - is intended to test the algorithm given a number of different scenarios
 - demonstrates theoretical efficacy
 - is not representative of "real-life" errors
"""

import argparse
import sqlite3
from tempfile import NamedTemporaryFile
from pathlib import Path
from typing import Sequence, Set, TextIO, Type, cast

from tqdm import tqdm

from sensibility import (
    Vectors, Corpus, SourceFile,
    Edit, Insertion, Deletion, Substitution
)
from sensibility._paths import VECTORS_PATH, SOURCES_PATH, DATA_DIR
from sensibility.abram import at_most
from sensibility.tokenize_js import check_syntax_file
from sensibility.mutations import Mutations
from sensibility.predictions import Predictions


# According to Campbell et al. 2014
MAX_MUTATIONS = 120

# Set up the argument parser
parser = argparse.ArgumentParser()
parser.add_argument('fold', type=int)
parser.add_argument('-k', '--mutations', type=int, default=MAX_MUTATIONS)
parser.add_argument('-n', '--limit', type=int, default=None)
parser.add_argument('-o', '--offset', type=int, default=0)


def syntax_ok(filename: str) -> bool:
    """
    Check if the syntax is okay.
    """
    with open(filename, 'rt') as source_file:
        return check_syntax_file(cast(TextIO, source_file))


def main() -> None:
    # Requires: corpus, model data (backwards and forwards)
    args = parser.parse_args()

    fold: int = args.fold
    test_set_filename: Path = DATA_DIR / f'test_set_hashes.{fold}'
    limit: int = args.limit
    offset: int = args.offset

    SourceFile.vectors = Vectors.connect_to(VECTORS_PATH)
    SourceFile.corpus = Corpus.connect_to(SOURCES_PATH)

    # Loads the parallel models.
    predictions = Predictions(fold)

    # Load the test set. Assume the file hashes are already in random order.
    with open(str(test_set_filename)) as test_set_file:
        test_set = tuple(line.strip() for line in test_set_file
                         if line.strip())

    # Resize the test set
    # TODO: find offset based on file hash
    upper_bound = offset + limit if limit is not None else len(test_set)
    test_set = test_set[offset:upper_bound]

    print(f"Considering {len(test_set)} test files to mutate...")

    # Mutate each file in the test set.
    with Mutations() as persist:
        progress = tqdm(test_set)
        for file_hash in progress:
            progress.set_description(file_hash)
            program = SourceFile(file_hash)
            mutate_file(program, persist, predictions, args.mutations)


CONTEXT_LENGTH = 20
SENTENCE_LENGTH = CONTEXT_LENGTH + 1
MIN_LENGTH = SENTENCE_LENGTH * 2

mutation_kinds: Sequence[Type[Edit]] = (Insertion, Deletion, Substitution)


def mutate_file(program: SourceFile,
                persist: Mutations,
                sensibility: Predictions,
                max_mutations_global: int):
    usable_length = len(program.vector) - MIN_LENGTH

    # Ignore files that are too short.
    if usable_length < 0:
        return

    persist.program = program

    # Clear the LRU cache for the new file.
    sensibility.clear_cache()

    progress = tqdm(total=max_mutations_global * len(mutation_kinds),
                    leave=False)
    for mutation_kind in mutation_kinds:
        failures = 0
        mutations_seen: Set[Edit] = set()

        # Clamp down the maximum number of mutations.
        max_mutations = at_most(max_mutations_global, usable_length)
        max_failures = max_mutations

        while failures < max_failures and len(mutations_seen) < max_mutations:
            vector = program.vector
            mutation: Edit = mutation_kind.create_random_mutation(vector)
            if mutation in mutations_seen:
                failures += 1
                continue
            mutations_seen.add(mutation)
            mutant = mutation.apply(vector)

            # Write out the mutated file.
            with NamedTemporaryFile(mode='w+', encoding='UTF-8') as mutant_file:
                # Apply the mutatation and write it to disk.
                mutant.print(file=mutant_file)
                mutant_file.flush()

                # Try the file, reject if it compiles.
                if syntax_ok(mutant_file.name):
                    # TODO: Store a vector of LINE NUMBERS.
                    # Hacky, but less error-prone than current solution.
                    persist.add_correct_file(mutation)
                    failures += 1
                    continue

                # Do it!
                sensibility.predict(mutant_file.name)

            persist.add_mutant(mutation)
            progress.update(1)

            # Update the description.
            progress.set_description(
                f'{mutation_kind.code}:{len(mutations_seen):d}/({failures})'
            )

    # Close the tqdm progress bar.
    progress.close()


if __name__ == '__main__':
    main()
